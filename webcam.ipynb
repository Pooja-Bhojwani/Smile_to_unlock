{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module is the main module in this package. It loads emotion recognition model from a file,\n",
    "shows a webcam image, recognizes face and it's emotion and draw emotion on the image.\n",
    "\"\"\"\n",
    "from cv2 import WINDOW_NORMAL\n",
    "\n",
    "import cv2\n",
    "from face_detect import find_faces\n",
    "from image_commons import nparray_as_image, draw_with_alpha\n",
    "\n",
    "\n",
    "def _load_emoticons(emotions):\n",
    "    \"\"\"\n",
    "    Loads emotions images from graphics folder.\n",
    "    :param emotions: Array of emotions names.\n",
    "    :return: Array of emotions graphics.\n",
    "    \"\"\"\n",
    "    return [nparray_as_image(cv2.imread('graphics/%s.png' % emotion, -1), mode=None) for emotion in emotions]\n",
    "\n",
    "\n",
    "def show_webcam_and_run(model, emoticons, window_size=None, window_name='webcam', update_time=10):\n",
    "    \"\"\"\n",
    "    Shows webcam image, detects faces and its emotions in real time and draw emoticons over those faces.\n",
    "    :param model: Learnt emotion detection model.\n",
    "    :param emoticons: List of emotions images.\n",
    "    :param window_size: Size of webcam image window.\n",
    "    :param window_name: Name of webcam image window.\n",
    "    :param update_time: Image update time interval.\n",
    "    \"\"\"\n",
    "    cv2.namedWindow(window_name, WINDOW_NORMAL)\n",
    "    if window_size:\n",
    "        width, height = window_size\n",
    "        cv2.resizeWindow(window_name, width, height)\n",
    "\n",
    "    vc = cv2.VideoCapture(0)\n",
    "    if vc.isOpened():\n",
    "        read_value, webcam_image = vc.read()\n",
    "    else:\n",
    "        print(\"webcam not found\")\n",
    "        return\n",
    "\n",
    "    while read_value:\n",
    "        for normalized_face, (x, y, w, h) in find_faces(webcam_image):\n",
    "            prediction = model.predict(normalized_face)  # do prediction\n",
    "            if cv2.__version__ != '3.1.0':\n",
    "                prediction = prediction[0]\n",
    "\n",
    "            image_to_draw = emoticons[prediction]\n",
    "            draw_with_alpha(webcam_image, image_to_draw, (x, y, w, h))\n",
    "\n",
    "        cv2.imshow(window_name, webcam_image)\n",
    "        read_value, webcam_image = vc.read()\n",
    "        key = cv2.waitKey(update_time)\n",
    "\n",
    "        if key == 27:  # exit on ESC\n",
    "            break\n",
    "\n",
    "    cv2.destroyWindow(window_name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    emotions = ['neutral', 'anger', 'disgust', 'happy', 'sadness', 'surprise']\n",
    "    emoticons = _load_emoticons(emotions)\n",
    "\n",
    "    # load model\n",
    "    if cv2.__version__ == '3.1.0':\n",
    "        fisher_face = cv2.face.createFisherFaceRecognizer()\n",
    "    else:\n",
    "        fisher_face = cv2.createFisherFaceRecognizer()\n",
    "    fisher_face.load('models/emotion_detection_model.xml')\n",
    "\n",
    "    # use learnt model\n",
    "    window_name = 'WEBCAM (press ESC to exit)'\n",
    "    show_webcam_and_run(fisher_face, emoticons, window_size=(1600, 1200), window_name=window_name, update_time=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
